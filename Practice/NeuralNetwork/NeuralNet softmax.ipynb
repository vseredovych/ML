{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В цій практичній роботі ми спробуємо реалізувати нейронну мережу з двох шарів (прихований і вихідний). Запропонований підхід стане заготовкою для реалізації наступних оптимізацій: MBGD, ADAM та регуляризації. \n",
    "\n",
    "Сьогодні ж вам пропонується додати до цього класу підтримку довільної кількості шарів та нейронів в них (наприклад, передавати їх параметром в конструктор, як це робиться в MLPClassifier за допомогою hidden_layer_sizes). Також потрібно передбачити можливість ранньої зупинки ітераційного процесу, якщо значення штрафної функції не покращуватиметься протягом певної кількості ітерацій. Наприклад, якщо протягом $k$ ітерацій штрафна функція за модулем не стане меншою, ніж на поточному кроці."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surface(cls, x_1, x_2, ax=None, threshold=0.5, contourf=False):\n",
    "    xx1, xx2 = np.meshgrid(np.linspace(x_1.min(), x_1.max(), 100), \n",
    "                           np.linspace(x_2.min(), x_2.max(), 100))\n",
    "\n",
    "    X_pred = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "    pred = cls.predict_proba(X_pred)[:, 0]\n",
    "    Z = pred.reshape((100, 100))\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.contour(xx1, xx2, Z, levels=[threshold], colors='black')\n",
    "    ax.set_xlim((x_1.min(), x_1.max()))\n",
    "    ax.set_ylim((x_2.min(), x_2.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_data(X, y):\n",
    "#     ax = plt.gca()\n",
    "#     ax.scatter(X[:,0], X[:,1], c=(y == 1), cmap=cm_bright)\n",
    "    \n",
    "def plot_data(A, b, test = False):\n",
    "    positive_indices = np.where(b == 1)[0]\n",
    "    negative_indices = np.where(b == 0)[0]\n",
    "    \n",
    "    plt.scatter(A[positive_indices, 0], A[positive_indices, 1], marker='x', c= 'yellow' if test else 'green')\n",
    "    plt.scatter(A[negative_indices, 0], A[negative_indices, 1], marker='+', c= 'blue' if test else 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    \"\"\"\n",
    "    NN for binary classification\n",
    "    Attributes:\n",
    "    ...\n",
    "    \"\"\"\n",
    "    # hidden_layer_sizes=(100, 50,)\n",
    "    def __init__(self, hidden_layer_sizes, normalize = True, learning_rate = 0.01, num_iter = 30000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iter = num_iter\n",
    "        self.normalize = normalize\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "    \n",
    "    def __normalize(self, X, mean = None, std = None):\n",
    "        \"\"\"\n",
    "        Зверніть увагу, що нормалізація вхідних даних є дуже важливою для швидкодії нейронних мереж.\n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "#         if m is None:\n",
    "#             m = np.mean(X, axis=1).reshape((n, 1))\n",
    "#         s = std\n",
    "#         if s is None:\n",
    "#             s = np.std(X, axis=1).reshape((n, 1))\n",
    "#         X_new = (X - m) / s**2\n",
    "#         return X_new, m, s\n",
    "    \n",
    "        if mean is None:   \n",
    "            mean = np.zeros([n, 1])\n",
    "        if std is None:\n",
    "            std  = np.ones([n, 1])\n",
    "        \n",
    "        for i in range(n):\n",
    "            if (np.std(X[:, i]) != 0):\n",
    "                if mean is None:\n",
    "                    mean[i] = np.mean(X[:, i])\n",
    "                if std is None:\n",
    "                    std[i] = np.std(X[:, i])\n",
    "        \n",
    "        X_new = (X - mean) / std\n",
    "        return X_new, mean, std\n",
    "    \n",
    "\n",
    "    def __sigmoid(self, Z):\n",
    "        \"\"\"\n",
    "        В наступних практичних потрібно буде додати підтримку й інших активаційних функцій - це один з гіперпараметрів. \n",
    "        Їх можна вибирати для всіх шарів одночасно або мати різні активаційні функції на кожному з них.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def __sigmoid_derivative(self, Z):\n",
    "        z = self.__sigmoid(Z)\n",
    "        return np.multiply(z, (1 - z))\n",
    "    \n",
    "    def __softmax(self, Z):\n",
    "        exp_z = np.exp(Z)\n",
    "        return exp_z / exp_z.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    def __cross_entropy(self, A, Y):\n",
    "        return - np.sum(Y * np.log(A), axis=1)\n",
    "    \n",
    "    def __initialize_parameters(self, n_x, n_y):\n",
    "        self.parameters = {}\n",
    "        n = len(n_x)\n",
    "        \n",
    "        for i in range(1, len(n_x)):\n",
    "            if (i == n):\n",
    "                continue\n",
    "            W = np.random.randn(n_x[i], n_x[i - 1]) * 0.01\n",
    "            b = np.zeros((n_x[i], 1))\n",
    "            self.parameters.update({f\"W{i}\": W, f\"b{i}\": b})\n",
    "\n",
    "        W = np.random.randn(n_y, n_x[n-1]) * 0.01\n",
    "        b = np.zeros((n_y, 1))\n",
    "        \n",
    "        self.parameters.update({f\"W{n}\":W, f\"b{n}\":b})\n",
    "                    \n",
    "    def __forward_propagation(self, X):\n",
    "        num_layers = len(self.hidden_layer_sizes)\n",
    "        cache = self.parameters.copy()\n",
    "        \n",
    "        A = X\n",
    "        for i in range(1, num_layers + 2):\n",
    "            if i == num_layers + 1:\n",
    "                W = self.parameters[f\"W{i}\"]\n",
    "                b = self.parameters[f\"b{i}\"]\n",
    "                Z = np.dot(W, A) + b\n",
    "                A = self.__softmax(Z)\n",
    "            else:            \n",
    "                W = self.parameters[f\"W{i}\"]\n",
    "                b = self.parameters[f\"b{i}\"]\n",
    "                Z = np.dot(W, A) + b\n",
    "                A = self.__sigmoid(Z)\n",
    "            cache.update({f\"Z{i}\": Z})\n",
    "            cache.update({f\"A{i}\": A})\n",
    "        return A, cache\n",
    "\n",
    "    def compute_cost(self, A, Y):\n",
    "        J = -np.mean(Y.T * np.log(A.T))\n",
    "        return J\n",
    "    \n",
    "    def __backward_propagation(self, X, Y, cache):\n",
    "        m = X.shape[1]\n",
    "        n = X.shape[0]\n",
    "        num_layers = len(self.hidden_layer_sizes)\n",
    "        \n",
    "        grads = {}\n",
    "        \n",
    "        for i in range(num_layers+1, 0, -1):\n",
    "            W = cache[f\"W{i}\"]\n",
    "            b = cache[f\"b{i}\"]\n",
    "            Z = cache[f\"Z{i}\"]\n",
    "            if i == num_layers + 1:\n",
    "                A = cache[f\"A{i}\"]\n",
    "                A_next = cache[f\"A{i - 1}\"]\n",
    "                \n",
    "                dZ = A - Y\n",
    "                dW = 1. / m * np.dot(dZ, A_next.T)\n",
    "                db = 1. / m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "            elif (i == 1):\n",
    "                W_prev = cache[f\"W{i + 1}\"]\n",
    "                A = cache[f\"A{i}\"]\n",
    "                \n",
    "                dA = np.dot(W_prev.T, dZ)\n",
    "                dZ = np.multiply(dA, self.__sigmoid_derivative(A))\n",
    "                dW = 1. / m * np.dot(dZ, X.T)\n",
    "                db = 1. / m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "            else:\n",
    "                W_prev = cache[f\"W{i + 1}\"]\n",
    "                A = cache[f\"A{i}\"]\n",
    "                A_next = cache[f\"A{i - 1}\"]\n",
    "\n",
    "                dA = np.dot(W_prev.T, dZ)\n",
    "                dZ = np.multiply(dA, self.__sigmoid_derivative(A))\n",
    "                dW = 1. / m * np.dot(dZ, A_next.T)\n",
    "                db = 1. / m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "            grads.update({f\"dZ{i}\":dZ, f\"dW{i}\":dW, f\"db{i}\":db})\n",
    "        return grads\n",
    "    \n",
    "    def __update_parameters(self, grads):\n",
    "        num_layers = len(self.hidden_layer_sizes)\n",
    "        \n",
    "        for i in range(1, num_layers + 2):\n",
    "            W = self.parameters[f\"W{i}\"]\n",
    "            b = self.parameters[f\"b{i}\"]\n",
    "            \n",
    "            dW = grads[f\"dW{i}\"]\n",
    "            db = grads[f\"db{i}\"]\n",
    "            \n",
    "            self.parameters[f\"W{i}\"] = W - self.learning_rate * dW\n",
    "            self.parameters[f\"b{i}\"] = b - self.learning_rate * db\n",
    "            \n",
    "    def fit(self, X_vert, Y_vert, epsilon=1e-08, print_cost = True):\n",
    "        \n",
    "        X, Y = X_vert.T, Y_vert.T\n",
    "        \n",
    "        if self.normalize:\n",
    "            X, self.__mean, self.__std = self.__normalize(X)\n",
    "        \n",
    "        costs = []\n",
    "        \n",
    "        m = X.shape[1]\n",
    "        n_x = (X.shape[0],) + self.hidden_layer_sizes\n",
    "        n_y = Y.shape[0]\n",
    "        \n",
    "        self.__initialize_parameters(n_x, n_y)\n",
    "        \n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "            A, cache = self.__forward_propagation(X)\n",
    "\n",
    "            cost = self.compute_cost(A, Y)\n",
    "\n",
    "            grads = self.__backward_propagation(X, Y, cache)\n",
    "\n",
    "            self.__update_parameters(grads)\n",
    "\n",
    "            costs.append(cost)\n",
    "\n",
    "            if print_cost and i % 1000 == 0:\n",
    "                print(\"{}-th iteration: {}\".format(i, cost))\n",
    "                if i > 1:\n",
    "                    print(f\"Delta: {costs[-2] - costs[-1]}\")\n",
    "       \n",
    "            if i > 1 and abs(costs[-2] - costs[-1]) < epsilon:\n",
    "                break\n",
    "                \n",
    "        if print_cost:\n",
    "            plt.plot(costs)\n",
    "            plt.ylabel(\"Cost\")\n",
    "            plt.xlabel(\"Iteration, *1000\")\n",
    "            plt.show()\n",
    "\n",
    "    def predict_proba(self, X_vert):\n",
    "        X = X_vert.T\n",
    "        if self.normalize:\n",
    "            X, _, _ = self.__normalize(X, self.__mean, self.__std)\n",
    "        \n",
    "        probs = self.__forward_propagation(X)[0]\n",
    "        return probs.T\n",
    "    \n",
    "    def predict(self, X_vert):\n",
    "        positive_probs = self.predict_proba(X_vert)\n",
    "        y_pred = self.likehood_func(positive_probs)\n",
    "        return y_pred  \n",
    "\n",
    "    def likehood_func(self, z):\n",
    "        return z.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спочатку спробуйте цей клас на одній задачі, а потім на іншій."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: X=(150, 4), y=(150, 1)\n"
     ]
    }
   ],
   "source": [
    "data_columns = [\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\"]\n",
    "target_column = \"Species\"\n",
    "df = pd.read_csv(\"iris.csv\")\n",
    "X, Y = df[data_columns].values, df[target_column].values.reshape((df.shape[0], 1))\n",
    "print('Training set: X={}, y={}'.format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Training set: X=(120, 4), y=(120, 3)\n",
      "Test set: X=(30, 4), y=(30, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train).toarray()\n",
    "y_labels =  [ label[3:] for label in encoder.get_feature_names()]\n",
    "\n",
    "print(type(y_train))\n",
    "print('Training set: X={}, y={}'.format(X_train.shape, y_train.shape))\n",
    "print('Test set: X={}, y={}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th iteration: 0.3663558901524471\n",
      "1000-th iteration: 0.14201478199378925\n",
      "Delta: 8.448603385974307e-06\n",
      "2000-th iteration: 0.04581596658361147\n",
      "Delta: 4.326167683920551e-05\n",
      "3000-th iteration: 0.025067722947965197\n",
      "Delta: 9.387905134970037e-06\n",
      "4000-th iteration: 0.019215117717208623\n",
      "Delta: 3.66464157477292e-06\n",
      "5000-th iteration: 0.016528486851788562\n",
      "Delta: 1.97192909656696e-06\n",
      "6000-th iteration: 0.014976677870412439\n",
      "Delta: 1.219505177800853e-06\n",
      "7000-th iteration: 0.01397168072837043\n",
      "Delta: 8.311199515154827e-07\n",
      "8000-th iteration: 0.013257350236035107\n",
      "Delta: 6.179589117100842e-07\n",
      "9000-th iteration: 0.012706179768384654\n",
      "Delta: 4.954134930155313e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cls = NeuralNet((20, 10), normalize = True, learning_rate = 0.5, num_iter = 100)\n",
    "#cls.fit(X_train, y_train.values.reshape((X_train.shape[0], 1)), epsilon=1e-15)\n",
    "\n",
    "cls = NeuralNet((50, ), normalize = True, learning_rate = 0.1, num_iter = 10000)\n",
    "cls.fit(X_train, y_train, epsilon=1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[-1.58730938e-01,  6.31338696e-01, -2.25851332e+00,\n",
      "        -1.41786006e+00],\n",
      "       [-2.43970531e-01, -5.04166443e-01,  8.46912851e-01,\n",
      "         5.15959384e-01],\n",
      "       [-9.17220447e-01,  9.28315108e-02, -3.18326745e+00,\n",
      "        -2.58080403e+00],\n",
      "       [ 6.01860178e-02,  8.11324316e-01, -1.87352939e+00,\n",
      "        -9.70376545e-01],\n",
      "       [-4.29545462e-01, -8.08050249e-01,  1.44252841e+00,\n",
      "         1.00008204e+00],\n",
      "       [-7.14631577e-01,  2.08963192e-01, -2.94567587e+00,\n",
      "        -2.23466305e+00],\n",
      "       [-2.22949104e-02,  7.21977533e-01, -2.04880569e+00,\n",
      "        -1.17493831e+00],\n",
      "       [-3.04039105e-01, -1.37072015e-01, -9.55319651e-02,\n",
      "        -2.66620955e-01],\n",
      "       [-3.84324395e-01,  4.87881195e-01, -2.68302488e+00,\n",
      "        -1.86091145e+00],\n",
      "       [ 8.72616962e-02,  8.09718336e-01, -1.91048575e+00,\n",
      "        -9.94124997e-01],\n",
      "       [ 1.81565493e-01,  9.66673702e-01, -1.70226111e+00,\n",
      "        -6.40396899e-01],\n",
      "       [-1.94789269e-01,  6.44328643e-01, -2.44126773e+00,\n",
      "        -1.55387743e+00],\n",
      "       [-7.97760926e-01,  1.55409768e-01, -3.10502530e+00,\n",
      "        -2.41939968e+00],\n",
      "       [-1.48550549e-01,  6.40546866e-01, -2.25420637e+00,\n",
      "        -1.37799773e+00],\n",
      "       [-4.39339043e-01, -7.26929477e-01,  1.20666907e+00,\n",
      "         7.70706833e-01],\n",
      "       [-3.44213533e-01,  5.02048861e-01, -2.57807093e+00,\n",
      "        -1.76906198e+00],\n",
      "       [-1.81770610e-01, -1.97410301e-01,  2.16098888e-01,\n",
      "        -2.47570595e-03],\n",
      "       [-5.01714328e-01,  3.83057378e-01, -2.89226423e+00,\n",
      "        -2.08579945e+00],\n",
      "       [-2.14241127e-01,  6.08733252e-01, -2.41935233e+00,\n",
      "        -1.59461357e+00],\n",
      "       [-8.31753083e-01,  2.11967436e-01, -3.31214324e+00,\n",
      "        -2.59839878e+00],\n",
      "       [-8.83364140e-02,  6.90019288e-01, -2.19831675e+00,\n",
      "        -1.33188458e+00],\n",
      "       [-3.92806146e-01,  4.78754435e-01, -2.65638406e+00,\n",
      "        -1.84953368e+00],\n",
      "       [ 1.53983779e-01,  8.67882000e-01, -1.71717704e+00,\n",
      "        -7.36740749e-01],\n",
      "       [-2.34164560e-01, -4.62897779e-01,  7.90538186e-01,\n",
      "         4.38074013e-01],\n",
      "       [-8.15053001e-02,  6.88500184e-01, -2.13046269e+00,\n",
      "        -1.28270996e+00],\n",
      "       [ 1.31991730e-01,  9.04406756e-01, -1.74718467e+00,\n",
      "        -7.43327581e-01],\n",
      "       [-4.56681215e-01, -9.45399877e-01,  1.83522556e+00,\n",
      "         1.43521591e+00],\n",
      "       [-2.07993893e-01, -4.36858131e-01,  7.45118276e-01,\n",
      "         4.26211410e-01],\n",
      "       [-8.74031391e-01,  1.19827734e-01, -3.16833851e+00,\n",
      "        -2.53195110e+00],\n",
      "       [-3.98280934e-01, -6.64191056e-01,  1.13676131e+00,\n",
      "         7.24300940e-01],\n",
      "       [ 1.64275175e-01,  8.80857315e-01, -1.75406943e+00,\n",
      "        -7.43846597e-01],\n",
      "       [-4.12039906e-01,  4.68869532e-01, -2.65395211e+00,\n",
      "        -1.83055721e+00],\n",
      "       [-9.55918705e-03,  7.47431619e-01, -1.99270184e+00,\n",
      "        -1.11075495e+00],\n",
      "       [-9.24909671e-01,  9.75946951e-03, -2.89075539e+00,\n",
      "        -2.39657103e+00],\n",
      "       [-4.77445927e-01,  4.02876502e-01, -2.83235563e+00,\n",
      "        -2.00772893e+00],\n",
      "       [-8.39528831e-01,  1.18735987e-01, -3.13698220e+00,\n",
      "        -2.49130907e+00],\n",
      "       [-1.80818757e-01, -2.00037813e-01,  3.18452462e-01,\n",
      "         8.70582597e-02],\n",
      "       [-4.68447931e-01,  4.46420618e-01, -2.77780258e+00,\n",
      "        -1.97874585e+00],\n",
      "       [-8.06521930e-01,  1.78220259e-01, -3.16797911e+00,\n",
      "        -2.48058383e+00],\n",
      "       [-1.61240063e-01, -1.63718408e-01,  3.05882789e-01,\n",
      "         9.90431581e-02],\n",
      "       [ 1.44673892e-01,  8.61355613e-01, -1.68396673e+00,\n",
      "        -7.02793941e-01],\n",
      "       [-2.50227657e-01,  6.04053092e-01, -2.50936768e+00,\n",
      "        -1.63383089e+00],\n",
      "       [-1.43716597e-01, -1.87930278e-01,  3.33703985e-01,\n",
      "         1.18252132e-01],\n",
      "       [ 6.52645218e-03,  7.70572839e-01, -2.02904905e+00,\n",
      "        -1.11429736e+00],\n",
      "       [-1.69121432e-01, -2.08096279e-01,  3.49164863e-01,\n",
      "         1.12858283e-01],\n",
      "       [ 7.03451914e-03,  7.50251508e-01, -1.98812809e+00,\n",
      "        -1.08485270e+00],\n",
      "       [ 6.38019690e-02,  7.97726636e-01, -1.88963548e+00,\n",
      "        -9.98618701e-01],\n",
      "       [-3.15157808e+00, -4.17217814e+00,  4.08360744e+00,\n",
      "         8.85447446e+00],\n",
      "       [-2.36078032e-01, -3.68210391e-01,  6.32360540e-01,\n",
      "         3.31111957e-01],\n",
      "       [-8.67335574e-01,  1.06598075e-01, -3.18447965e+00,\n",
      "        -2.53207257e+00]]), 'b1': array([[ 2.65584912e-01],\n",
      "       [-1.51375344e-01],\n",
      "       [ 4.28866338e-01],\n",
      "       [ 1.95590703e-01],\n",
      "       [-3.13917112e-01],\n",
      "       [ 3.72175029e-01],\n",
      "       [ 2.31114821e-01],\n",
      "       [ 4.77324572e-02],\n",
      "       [ 3.27044138e-01],\n",
      "       [ 2.02122159e-01],\n",
      "       [ 1.27114013e-01],\n",
      "       [ 2.91511815e-01],\n",
      "       [ 4.01632593e-01],\n",
      "       [ 2.63415250e-01],\n",
      "       [-2.37025300e-01],\n",
      "       [ 3.10246513e-01],\n",
      "       [-3.62701745e-04],\n",
      "       [ 3.52733625e-01],\n",
      "       [ 2.89474537e-01],\n",
      "       [ 4.33392143e-01],\n",
      "       [ 2.51836705e-01],\n",
      "       [ 3.22779867e-01],\n",
      "       [ 1.54686913e-01],\n",
      "       [-1.31692355e-01],\n",
      "       [ 2.44832236e-01],\n",
      "       [ 1.50500908e-01],\n",
      "       [-4.35633137e-01],\n",
      "       [-1.23450489e-01],\n",
      "       [ 4.20540084e-01],\n",
      "       [-2.20982780e-01],\n",
      "       [ 1.52095706e-01],\n",
      "       [ 3.23008859e-01],\n",
      "       [ 2.19035148e-01],\n",
      "       [ 3.96982970e-01],\n",
      "       [ 3.46692160e-01],\n",
      "       [ 4.10099958e-01],\n",
      "       [-1.64241538e-02],\n",
      "       [ 3.41031375e-01],\n",
      "       [ 4.10425575e-01],\n",
      "       [-1.52688052e-02],\n",
      "       [ 1.45673975e-01],\n",
      "       [ 3.01128445e-01],\n",
      "       [-2.26492604e-02],\n",
      "       [ 2.27867074e-01],\n",
      "       [-2.35155142e-02],\n",
      "       [ 2.17479221e-01],\n",
      "       [ 1.99235150e-01],\n",
      "       [-3.64519046e+00],\n",
      "       [-8.59388739e-02],\n",
      "       [ 4.20075126e-01]]), 'W2': array([[ 0.74052597, -0.52442533,  0.21571059,  0.97244284, -0.80844709,\n",
      "         0.31851204,  0.8650938 ,  0.0408284 ,  0.58906582,  1.01207136,\n",
      "         1.11772699,  0.75424292,  0.27360606,  0.7543066 , -0.73749561,\n",
      "         0.58031642, -0.14281674,  0.4927974 ,  0.70692449,  0.31616097,\n",
      "         0.7937175 ,  0.57610733,  1.09929178, -0.49374562,  0.81044556,\n",
      "         1.03561651, -0.8993532 , -0.46834455,  0.24284565, -0.68892095,\n",
      "         1.06898028,  0.55721367,  0.8713363 ,  0.16079247,  0.50057388,\n",
      "         0.24117755, -0.1580593 ,  0.5359515 ,  0.29134523, -0.0882851 ,\n",
      "         1.0509741 ,  0.70534249, -0.11574469,  0.93174508, -0.16677242,\n",
      "         0.8875203 ,  0.97412919, -0.82762719, -0.34368416,  0.23871217],\n",
      "       [-0.27116894,  0.33183806,  0.31941829, -0.50465857,  0.47945831,\n",
      "         0.14443707, -0.40305877,  0.32884683, -0.09527855, -0.5317647 ,\n",
      "        -0.66499906, -0.24256492,  0.22002687, -0.27452831,  0.46331319,\n",
      "        -0.14190757,  0.27442489, -0.00900309, -0.23386393,  0.23656314,\n",
      "        -0.3410705 , -0.08900794, -0.6166301 ,  0.31034326, -0.34048101,\n",
      "        -0.60292375,  0.43820746,  0.29349658,  0.28644732,  0.43808876,\n",
      "        -0.61875252, -0.08147454, -0.42349799,  0.35138053, -0.03701653,\n",
      "         0.25886618,  0.26308489, -0.04142721,  0.22558717,  0.2373126 ,\n",
      "        -0.60322086, -0.19624404,  0.22211806, -0.4484757 ,  0.25198335,\n",
      "        -0.43775898, -0.49737332, -5.38761531,  0.3043434 ,  0.29292477],\n",
      "       [-0.46751917,  0.19273176, -0.56327734, -0.45424185,  0.29940062,\n",
      "        -0.4663858 , -0.47167713, -0.383799  , -0.48613267, -0.48522664,\n",
      "        -0.43672748, -0.495019  , -0.499761  , -0.46243755,  0.24196296,\n",
      "        -0.48765872, -0.15994191, -0.48514888, -0.49271251, -0.54985035,\n",
      "        -0.47440747, -0.47402574, -0.46743672,  0.17570896, -0.46132967,\n",
      "        -0.43031506,  0.45080903,  0.17487923, -0.53124082,  0.24679319,\n",
      "        -0.44671479, -0.47521039, -0.45676051, -0.53481576, -0.49861478,\n",
      "        -0.50770461, -0.08697963, -0.48263403, -0.50704666, -0.12235784,\n",
      "        -0.44451275, -0.48814091, -0.10817806, -0.49036659, -0.06846996,\n",
      "        -0.46233191, -0.45571689,  6.20752498,  0.02212033, -0.5205119 ]]), 'b2': array([[ 0.76149568],\n",
      "       [ 1.90606647],\n",
      "       [-2.66756215]])}\n"
     ]
    }
   ],
   "source": [
    "print(cls.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99971355e-01, 2.83872489e-05, 2.58217334e-07],\n",
       "       [9.99863496e-01, 1.35162237e-04, 1.34165953e-06],\n",
       "       [9.99688134e-01, 3.09511506e-04, 2.35460124e-06],\n",
       "       [2.56729846e-04, 9.74460733e-01, 2.52825367e-02],\n",
       "       [2.90784016e-04, 1.15884620e-01, 8.83824596e-01],\n",
       "       [9.99842005e-01, 1.56533083e-04, 1.46181336e-06],\n",
       "       [1.34914881e-04, 9.98183612e-01, 1.68147338e-03],\n",
       "       [2.38457686e-04, 9.97907344e-01, 1.85419880e-03],\n",
       "       [4.57015098e-05, 7.73381432e-03, 9.92220484e-01],\n",
       "       [9.99979978e-01, 1.98421172e-05, 1.79881740e-07],\n",
       "       [4.91270089e-05, 8.07157067e-03, 9.91879302e-01],\n",
       "       [3.15603826e-04, 9.15632742e-01, 8.40516541e-02],\n",
       "       [4.69182519e-05, 7.74064892e-03, 9.92212433e-01],\n",
       "       [7.84172242e-04, 9.97013799e-01, 2.20202868e-03],\n",
       "       [5.47322238e-05, 1.06872232e-02, 9.89258045e-01],\n",
       "       [3.23129916e-04, 9.97780028e-01, 1.89684168e-03],\n",
       "       [1.49044471e-04, 9.97771099e-01, 2.07985642e-03],\n",
       "       [5.55925742e-04, 3.61587896e-01, 6.37856178e-01],\n",
       "       [9.99694984e-01, 3.02865013e-04, 2.15126773e-06],\n",
       "       [1.46691227e-03, 9.96157572e-01, 2.37551600e-03],\n",
       "       [3.53746113e-05, 8.74232235e-03, 9.91222303e-01],\n",
       "       [4.13635576e-05, 9.15554161e-03, 9.90803095e-01],\n",
       "       [9.99964770e-01, 3.49024366e-05, 3.27392703e-07],\n",
       "       [2.22926303e-04, 9.71242525e-01, 2.85345491e-02],\n",
       "       [2.48603931e-04, 9.97954255e-01, 1.79714157e-03],\n",
       "       [9.99932500e-01, 6.69080756e-05, 5.91617381e-07],\n",
       "       [9.99613443e-01, 3.83123232e-04, 3.43340161e-06],\n",
       "       [3.98244294e-05, 8.03419475e-03, 9.91925981e-01],\n",
       "       [3.19057593e-04, 9.97754026e-01, 1.92691615e-03],\n",
       "       [9.99890602e-01, 1.08294096e-04, 1.10353936e-06]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob = cls.predict_proba(X_test)\n",
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = cls.predict(X_test)\n",
    "Y_hat_labels = [y_labels[i] for i in Y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, Y_hat_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зверніть увагу на границю прийняття рішення. Модель старається побудувати складну криву, що може свідчити про її перетренування. Порівняйте отримані результати з класом з sklearn. Спробуйте додати нові шари для нашого класу та порівняти результати тоді. Поекспериментуйте з гіперпараметрами для обох класів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes = (20,10), max_iter = 11000, activation = 'relu', solver = 'sgd', learning_rate_init = 0.01, learning_rate = 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.01, max_fun=15000, max_iter=11000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred_labels = [y_labels[np.argmax(i)] for i in Y_pred]\n",
    "accuracy_score(y_test, Y_pred_labels)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit72af3e13b1864d0a85758af773701f9c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
